{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b57b834",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "This notebook presents initial data selection for complex sentences. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add8d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30cdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_jsonl(data, output_path, append=False, progress=False):\n",
    "    \"\"\"\n",
    "    Write list of objects to a JSON lines file.\n",
    "    \"\"\"\n",
    "    mode = 'a+' if append else 'w'\n",
    "    with open(output_path, mode, encoding='utf-8') as f:\n",
    "        if progress:\n",
    "            data = tqdm(data)\n",
    "            \n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + '\\n')\n",
    "    print('Wrote {} records to {}'.format(len(data), output_path))\n",
    "    \n",
    "def load_jsonl(input_path, progress=False) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        if progress:\n",
    "            f = tqdm(f)\n",
    "            \n",
    "        for line in f:\n",
    "                data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "            \n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257989e7",
   "metadata": {},
   "source": [
    "## Loading Data \n",
    "\n",
    "There are two text input files.\n",
    "* general texts for TF-IDF computation\n",
    "    * We will use this to calculate rare words using tf-idf\n",
    "    * In this file you will have each row as sentence/paragraph etc \n",
    "    * Need to very large min 200K sentences\n",
    "    \n",
    "* target source where complex sentences will be selected.\n",
    "    * We will use this to select the Complex sentence based on the different conditions\n",
    "    * In this file you will have each row as sentence with option to have categories (i.e. from where senetence is selected)\n",
    "    * Need to very large min 50K sentences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370369a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'D:\\rarewordshindi\\Textchunks'\n",
    "generic_file = '\\chunk_d.csv'\n",
    "generic = pd.read_csv(data_dir+generic_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "296e1695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  \\\n",
      "0        \"आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\"   \n",
      "1     \"इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिय...   \n",
      "2     \"मोदी सरकार के पहले कार्यकाल में भी तीन तलाक क...   \n",
      "3     \"भाजपा के दिवंगत नेता प्रमोद महाजन की बेटी पून...   \n",
      "4     \"ऐसी स्थिति में एक न्यायपूर्ण सरकार सार्वजनिक ...   \n",
      "...                                                 ...   \n",
      "2029  \"देश के सबसे पुराने राजनीतिक दल के अध्यक्ष से ...   \n",
      "2030  \"भारतीय हॉकी टीम के कप्तान मनप्रीत सिंह ने गोल...   \n",
      "2031  \"अगर ऐसा होता है तो दिशा इस शो में दो साल से अ...   \n",
      "2032  \"शिमला — कानपुर में खेली गई राष्ट्रीय स्कूल ता...   \n",
      "2033                    \"इसी दौरान पवन भी नहा  रहा था।\"   \n",
      "\n",
      "                                                  nouns  \n",
      "0                                                    []  \n",
      "1                                              [दुनिया]  \n",
      "2                                          [सरकार, पास]  \n",
      "3                                          [नेता, सचिव]  \n",
      "4                                  [स्थिति, सरकार, रूप]  \n",
      "...                                                 ...  \n",
      "2029                              [दल, अध्यक्ष, उम्मीद]  \n",
      "2030                     [हॉकी, टीम, कप्तान, सिंह, टीम]  \n",
      "2031                                       [साल, वापसी]  \n",
      "2032  [राष्ट्रीय, स्कूल, प्रदेश, टीम, सिंह, स्थान, प...  \n",
      "2033                                                 []  \n",
      "\n",
      "[2034 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import indian\n",
    "from nltk.tag import tnt\n",
    "\n",
    "# Make sure to download the required NLTK data\n",
    "nltk.download('indian')\n",
    "\n",
    "# Sample data: replace this with reading your actual CSV file using pd.read_csv('yourfile.csv')\n",
    "\n",
    "\n",
    "# Function to extract nouns from a Hindi text string\n",
    "def extract_nouns(text):\n",
    "    tokens = text.split()\n",
    "    train_data = indian.tagged_sents('hindi.pos')\n",
    "    tnt_pos_tagger = tnt.TnT()\n",
    "    tnt_pos_tagger.train(train_data)\n",
    "    tagged_words = tnt_pos_tagger.tag(tokens)\n",
    "    nouns = [word for word, tag in tagged_words if tag.startswith('NN')]\n",
    "    return nouns\n",
    "\n",
    "# Applying the function to each row in the DataFrame's 'text' column\n",
    "generic['nouns'] = generic['text'].apply(extract_nouns)\n",
    "\n",
    "# Print the DataFrame with an additional column for nouns\n",
    "print(generic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5ae5da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nouns</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\"</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[\"आवेदन, करने, की, आखिरी, तारीख, 31, जनवरी,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिय...</td>\n",
       "      <td>['दुनिया']</td>\n",
       "      <td>[[\"इतनी, दुआ, कर, दो, हमारे, लिए, कि, जितना, प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"मोदी सरकार के पहले कार्यकाल में भी तीन तलाक क...</td>\n",
       "      <td>['सरकार', 'पास']</td>\n",
       "      <td>[[\"मोदी, सरकार, के, पहले, कार्यकाल, में, भी, त...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"भाजपा के दिवंगत नेता प्रमोद महाजन की बेटी पून...</td>\n",
       "      <td>['नेता', 'सचिव']</td>\n",
       "      <td>[[\"भाजपा, के, दिवंगत, नेता, प्रमोद, महाजन, की,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"ऐसी स्थिति में एक न्यायपूर्ण सरकार सार्वजनिक ...</td>\n",
       "      <td>['स्थिति', 'सरकार', 'रूप']</td>\n",
       "      <td>[[\"ऐसी, स्थिति, में, एक, न्यायपूर्ण, सरकार, सा...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0     \"आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\"   \n",
       "1  \"इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिय...   \n",
       "2  \"मोदी सरकार के पहले कार्यकाल में भी तीन तलाक क...   \n",
       "3  \"भाजपा के दिवंगत नेता प्रमोद महाजन की बेटी पून...   \n",
       "4  \"ऐसी स्थिति में एक न्यायपूर्ण सरकार सार्वजनिक ...   \n",
       "\n",
       "                        nouns  \\\n",
       "0                          []   \n",
       "1                  ['दुनिया']   \n",
       "2            ['सरकार', 'पास']   \n",
       "3            ['नेता', 'सचिव']   \n",
       "4  ['स्थिति', 'सरकार', 'रूप']   \n",
       "\n",
       "                                              tokens  \n",
       "0  [[\"आवेदन, करने, की, आखिरी, तारीख, 31, जनवरी,, ...  \n",
       "1  [[\"इतनी, दुआ, कर, दो, हमारे, लिए, कि, जितना, प...  \n",
       "2  [[\"मोदी, सरकार, के, पहले, कार्यकाल, में, भी, त...  \n",
       "3  [[\"भाजपा, के, दिवंगत, नेता, प्रमोद, महाजन, की,...  \n",
       "4  [[\"ऐसी, स्थिति, में, एक, न्यायपूर्ण, सरकार, सा...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49e444a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\"'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "981ce323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: indic-nlp-library in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (0.92)\n",
      "Requirement already satisfied: sphinx-argparse in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from indic-nlp-library) (0.4.0)\n",
      "Requirement already satisfied: sphinx-rtd-theme in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from indic-nlp-library) (1.3.0)\n",
      "Requirement already satisfied: morfessor in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from indic-nlp-library) (2.0.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from indic-nlp-library) (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from indic-nlp-library) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->indic-nlp-library) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->indic-nlp-library) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->indic-nlp-library) (2023.3)\n",
      "Requirement already satisfied: sphinx>=1.2.0 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx-argparse->indic-nlp-library) (7.1.2)\n",
      "Requirement already satisfied: docutils<0.19 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx-rtd-theme->indic-nlp-library) (0.18.1)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.13 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.15.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.12.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
      "Requirement already satisfied: imagesize>=1.3 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n",
      "Requirement already satisfied: packaging>=21.0 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (6.8.0)\n",
      "Requirement already satisfied: colorama>=0.4.5 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata>=4.8->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.16.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from Jinja2>=3.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "! pip install indic-nlp-library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da4e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_sentence(text, lang=\"hi\"):\n",
    "    #If there is other way to split the sentence in your language please use option and change\n",
    "    \n",
    "    # Remove newline, tabs. \n",
    "    # You could add more things if needed\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "        \n",
    "    #You need to include your language Senetence Splitter\n",
    "    if lang == \"hi\": \n",
    "        text = text.lower()\n",
    "        sents = text.split('|') # could also split by '?' etc \n",
    "    elif lang == 'th':\n",
    "        from pythainlp.tokenize import sent_tokenize\n",
    "        sents = sent_tokenize(text)\n",
    "    return sents\n",
    "\n",
    "def word_tokenize(text, lang=\"hi\"):\n",
    "    #If there is other way to tokenize the sentence in your language please use option and change\n",
    "    #You need to include your language Word Tokenizer\n",
    "    if lang == \"hi\": \n",
    "        words = text.split(' ') #Lematize\n",
    "    elif lang == 'th':\n",
    "        from pythainlp.tokenize import word_tokenize\n",
    "        words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "\n",
    "def tokenize_sentence(text, lang=\"hi\"):\n",
    "    sents = split_sentence(text, lang=lang)\n",
    "    words = []\n",
    "    for s in sents:\n",
    "        w = word_tokenize(s, lang=lang)\n",
    "        words.append(w)\n",
    "    return words\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23e2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tokens(df):\n",
    "    tokens = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        words = tokenize_sentence(row[\"text\"])\n",
    "        tokens.append(words)\n",
    "    df[\"tokens\"] = tokens\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2101a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = generic.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a9f9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed59dc5064c4d82ba6da282225d19be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generic = add_tokens(generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a780f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nouns</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\"</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[\"आवेदन, करने, की, आखिरी, तारीख, 31, जनवरी,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिय...</td>\n",
       "      <td>['दुनिया']</td>\n",
       "      <td>[[\"इतनी, दुआ, कर, दो, हमारे, लिए, कि, जितना, प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"मोदी सरकार के पहले कार्यकाल में भी तीन तलाक क...</td>\n",
       "      <td>['सरकार', 'पास']</td>\n",
       "      <td>[[\"मोदी, सरकार, के, पहले, कार्यकाल, में, भी, त...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"भाजपा के दिवंगत नेता प्रमोद महाजन की बेटी पून...</td>\n",
       "      <td>['नेता', 'सचिव']</td>\n",
       "      <td>[[\"भाजपा, के, दिवंगत, नेता, प्रमोद, महाजन, की,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"ऐसी स्थिति में एक न्यायपूर्ण सरकार सार्वजनिक ...</td>\n",
       "      <td>['स्थिति', 'सरकार', 'रूप']</td>\n",
       "      <td>[[\"ऐसी, स्थिति, में, एक, न्यायपूर्ण, सरकार, सा...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0     \"आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\"   \n",
       "1  \"इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिय...   \n",
       "2  \"मोदी सरकार के पहले कार्यकाल में भी तीन तलाक क...   \n",
       "3  \"भाजपा के दिवंगत नेता प्रमोद महाजन की बेटी पून...   \n",
       "4  \"ऐसी स्थिति में एक न्यायपूर्ण सरकार सार्वजनिक ...   \n",
       "\n",
       "                        nouns  \\\n",
       "0                          []   \n",
       "1                  ['दुनिया']   \n",
       "2            ['सरकार', 'पास']   \n",
       "3            ['नेता', 'सचिव']   \n",
       "4  ['स्थिति', 'सरकार', 'रूप']   \n",
       "\n",
       "                                              tokens  \n",
       "0  [[\"आवेदन, करने, की, आखिरी, तारीख, 31, जनवरी,, ...  \n",
       "1  [[\"इतनी, दुआ, कर, दो, हमारे, लिए, कि, जितना, प...  \n",
       "2  [[\"मोदी, सरकार, के, पहले, कार्यकाल, में, भी, त...  \n",
       "3  [[\"भाजपा, के, दिवंगत, नेता, प्रमोद, महाजन, की,...  \n",
       "4  [[\"ऐसी, स्थिति, में, एक, न्यायपूर्ण, सरकार, सा...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a12570",
   "metadata": {},
   "source": [
    "## Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2016fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_tfidf(sents):\n",
    "    tfcounter = Counter()\n",
    "    dfcounter = Counter()\n",
    "    N = 0\n",
    "    for idx, row in tqdm(sents.iterrows(), total=len(sents)):\n",
    "        for s in row[\"tokens\"]:\n",
    "            N += 1\n",
    "            tfcounter.update(s)\n",
    "\n",
    "            uniqueTokens = list(set(s))\n",
    "            dfcounter.update(uniqueTokens)  \n",
    "\n",
    "    return N, tfcounter, dfcounter\n",
    "\n",
    "def save_tfidf(generic,tf_file_name,df_file_name):\n",
    "    N, tfcounter, dfcounter = get_tfidf(generic)\n",
    "    dump_jsonl([tfcounter], tf_file_name)\n",
    "    dump_jsonl([dfcounter], df_file_name)\n",
    "    \n",
    "    return N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d2dc11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\chunk_d'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_file[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ab90ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c830e045af443a9ac38f90b8ac6f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1 records to D:\\rarewordshindi\\Textchunks/tfcounter\\chunk_djsonl\n",
      "Wrote 1 records to D:\\rarewordshindi\\Textchunks/dfcounter\\chunk_djsonl\n"
     ]
    }
   ],
   "source": [
    "tf_file_name = data_dir + '/tfcounter'+generic_file[:-4]+'jsonl'\n",
    "df_file_name = data_dir + '/dfcounter'+generic_file[:-4]+'jsonl'\n",
    "\n",
    "N = save_tfidf(generic,tf_file_name,df_file_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481e6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_counter(filename):\n",
    "    counter = load_jsonl(filename)[0]\n",
    "    counter = pd.DataFrame([{\"term\":k, \"count\":counter[k]} for k in counter])\n",
    "    return counter\n",
    "\n",
    "def get_tfidfcounter(tf_file_name,df_file_name):\n",
    "    _tfcounter = load_counter(tf_file_name)\n",
    "    _dfcounter = load_counter(df_file_name)\n",
    "    _tfcounter.columns = [\"term\", \"tf\"]\n",
    "    _dfcounter.columns = [\"term\", \"df\"]\n",
    "    tfidfcounter = _tfcounter.merge(_dfcounter, on=\"term\")\n",
    "    return tfidfcounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31315ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 records from D:\\rarewordshindi\\Textchunks/tfcounter\\chunk_djsonl\n",
      "Loaded 1 records from D:\\rarewordshindi\\Textchunks/dfcounter\\chunk_djsonl\n"
     ]
    }
   ],
   "source": [
    "tfidfcounter = get_tfidfcounter(tf_file_name,df_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc32c5",
   "metadata": {},
   "source": [
    "## Select rare words\n",
    "\n",
    "Select only terms that \n",
    "* consider only terms that can be observed at least 5 times in the corpus\n",
    "* consider only Thai terms\n",
    "* consider only terms that longer than 5 charecters (remove noise from word tokenization as Thai also doesn't have clear word boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3888c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_based_on_length_occuurance(tfidfcounter, minTF=5, minWordLenth = 5):\n",
    "\n",
    "    tfidfcounter = tfidfcounter[tfidfcounter[\"tf\"] >= minTF]\n",
    "    tfidfcounter = tfidfcounter[tfidfcounter[\"term\"].apply(lambda x: len(x) > minWordLenth)]\n",
    "    \n",
    "    return tfidfcounter\n",
    "#You need to include your language specif minTF and minimum word length\n",
    "tfidfcounter = filter_based_on_length_occuurance(tfidfcounter, minTF=5,minWordLenth = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a48091",
   "metadata": {},
   "source": [
    "I used logarithmically scaled formular. Please [see](https://jmotif.github.io/sax-vsm_site/morea/algorithm/TFIDF.html) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab545f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = number of documents; in this case, it is number of sentences in the corpus\n",
    "tfidfcounter[\"tfidf\"] = np.log(1+tfidfcounter[\"tf\"]) * np.log(N/tfidfcounter[\"df\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569e261",
   "metadata": {},
   "source": [
    "Define a threshold for the rare words and get the set of rare words in rare_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "365e8b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    402.000000\n",
      "mean      12.359367\n",
      "std        1.326304\n",
      "min       10.802951\n",
      "25%       11.202771\n",
      "50%       12.158329\n",
      "75%       13.256673\n",
      "max       17.259000\n",
      "Name: tfidf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tfidf = tfidfcounter.sort_values(by=\"tfidf\", ascending=False).reset_index()\n",
    "print(tfidf[\"tfidf\"].describe())\n",
    "# ax = tfidf[\"tfidf\"].plot(title=\"TF-IDF\", xlabel=\"word index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9dc5099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             term  tf  df      tfidf\n",
      "35       कार्यकाल   5   5  10.802951\n",
      "45        हालांकि   6   6  11.377582\n",
      "86        प्रबंधन   6   6  11.377582\n",
      "93        चेयरमैन   5   4  11.202771\n",
      "158      ऐतिहासिक   5   5  10.802951\n",
      "...           ...  ..  ..        ...\n",
      "8759       शर्मा,   5   5  10.802951\n",
      "8956    कार्यकारी   5   4  11.202771\n",
      "9420   महाराष्ट्र   6   5  11.732363\n",
      "9849      नेतृत्व   5   5  10.802951\n",
      "10063      चुनावी   5   4  11.202771\n",
      "\n",
      "[163 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming tfidfcounter is a DataFrame that contains the TF-IDF scores and terms\n",
    "# You might have something like this, for example:\n",
    "# tfidfcounter = pd.DataFrame({'term': ['विद्यार्थी', 'student', 'खेल', 'game'], 'tfidf': [0.1, 0.2, 0.3, 0.4]})\n",
    "\n",
    "# Use 25% Quantile as threshold for rare words\n",
    "quantile = 0.45 # You could change this\n",
    "threshold = tfidfcounter[\"tfidf\"].quantile(quantile)\n",
    "selected_terms = tfidfcounter[tfidfcounter[\"tfidf\"] < threshold]\n",
    "\n",
    "# Filter out English terms using a regular expression\n",
    "selected_terms = selected_terms[~selected_terms['term'].str.contains(r'[a-zA-Z]', regex=True)]\n",
    "\n",
    "# Print the filtered selected terms that are only in Hindi\n",
    "print(selected_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d94ed156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tf</th>\n",
       "      <th>df</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>कार्यकाल</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>ऐतिहासिक</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>रैंकिंग</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>पहुंचने</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>समाधान</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>क्षेत्रीय</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>बेहतरीन</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8166</th>\n",
       "      <td>सीनियर</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>शर्मा,</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>नेतृत्व</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10.802951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           term  tf  df      tfidf\n",
       "35     कार्यकाल   5   5  10.802951\n",
       "158    ऐतिहासिक   5   5  10.802951\n",
       "253     रैंकिंग   5   5  10.802951\n",
       "681     पहुंचने   5   5  10.802951\n",
       "724      समाधान   5   5  10.802951\n",
       "...         ...  ..  ..        ...\n",
       "7410  क्षेत्रीय   5   5  10.802951\n",
       "7596    बेहतरीन   5   5  10.802951\n",
       "8166     सीनियर   5   5  10.802951\n",
       "8759     शर्मा,   5   5  10.802951\n",
       "9849    नेतृत्व   5   5  10.802951\n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "429893ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           term\n",
      "35     कार्यकाल\n",
      "158    ऐतिहासिक\n",
      "253     रैंकिंग\n",
      "681            \n",
      "724            \n",
      "...         ...\n",
      "7410  क्षेत्रीय\n",
      "7596    बेहतरीन\n",
      "8166     सीनियर\n",
      "8759     शर्मा,\n",
      "9849           \n",
      "\n",
      "[73 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_remove_nouns(text):\n",
    "    tokens = text.split()\n",
    "    train_data = indian.tagged_sents('hindi.pos')\n",
    "    tnt_pos_tagger = tnt.TnT()\n",
    "    tnt_pos_tagger.train(train_data)\n",
    "    tagged_words = tnt_pos_tagger.tag(tokens)\n",
    "    nouns = {word for word, tag in tagged_words if 'NN' in tag}\n",
    "    # Removing nouns from the original text\n",
    "    modified_text = ' '.join([word for word in tokens if word not in nouns])\n",
    "    return modified_text\n",
    "\n",
    "# Applying the function to each row in the DataFrame's 'term' column and updating it\n",
    "df['term'] = df['term'].apply(extract_and_remove_nouns)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33de8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('updated_terms.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f83dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44e466df",
   "metadata": {},
   "source": [
    "## Pre-filtering candidate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48fadd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = ''\n",
    "target = pd.read_csv(data_dir+target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50fcf5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"ਖੇਤੀਬਾੜੀ ਮੰਤਰਾਲਾ ਰਾਜਸਥਾਨ, ਮੱਧ ਪ੍ਰਦੇਸ਼, ਪੰਜਾਬ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ਅੱਤਵਾਦ ਨੂੰ ਕਿਸੇੇ ਧਰਮ ਨਾਲ ਨਹੀਂ ਜੋੜਿਆ ਜਾ ਸਕਦਾ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"ਲਿਊ ਨੇ ਕਿਹਾ, ਇਸ ਸਭ ਤੋਂ ਚੀਨ - ਭਾਰਤ ਸੀਮਾ ਪਾਰ ਵਿ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"ਉਸ ਮੁਤਾਬਿਕ ਅਗਲੀ ਕਾਰਵਾਈ ਕੀਤੀ ਜਾਵੇਗੀ।\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"ਕਈ ਸਾਲ ਬੀਤ ਗਏ ਅਤੇ ਸ਼ੇਲਾਹ ਵੱਡਾ ਹੋ ਗਿਆ ।\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  \"ਖੇਤੀਬਾੜੀ ਮੰਤਰਾਲਾ ਰਾਜਸਥਾਨ, ਮੱਧ ਪ੍ਰਦੇਸ਼, ਪੰਜਾਬ,...\n",
       "1  \"ਅੱਤਵਾਦ ਨੂੰ ਕਿਸੇੇ ਧਰਮ ਨਾਲ ਨਹੀਂ ਜੋੜਿਆ ਜਾ ਸਕਦਾ, ...\n",
       "2  \"ਲਿਊ ਨੇ ਕਿਹਾ, ਇਸ ਸਭ ਤੋਂ ਚੀਨ - ਭਾਰਤ ਸੀਮਾ ਪਾਰ ਵਿ...\n",
       "3              \"ਉਸ ਮੁਤਾਬਿਕ ਅਗਲੀ ਕਾਰਵਾਈ ਕੀਤੀ ਜਾਵੇਗੀ।\"\n",
       "4           \"ਕਈ ਸਾਲ ਬੀਤ ਗਏ ਅਤੇ ਸ਼ੇਲਾਹ ਵੱਡਾ ਹੋ ਗਿਆ ।\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b67d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1636898/1636898 [01:01<00:00, 26716.03it/s]\n"
     ]
    }
   ],
   "source": [
    "target = add_tokens(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32bfdd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"ਖੇਤੀਬਾੜੀ ਮੰਤਰਾਲਾ ਰਾਜਸਥਾਨ, ਮੱਧ ਪ੍ਰਦੇਸ਼, ਪੰਜਾਬ,...</td>\n",
       "      <td>[[\"ਖੇਤੀਬਾੜੀ, ਮੰਤਰਾਲਾ, ਰਾਜਸਥਾਨ,, ਮੱਧ, ਪ੍ਰਦੇਸ਼,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ਅੱਤਵਾਦ ਨੂੰ ਕਿਸੇੇ ਧਰਮ ਨਾਲ ਨਹੀਂ ਜੋੜਿਆ ਜਾ ਸਕਦਾ, ...</td>\n",
       "      <td>[[\"ਅੱਤਵਾਦ, ਨੂੰ, ਕਿਸੇੇ, ਧਰਮ, ਨਾਲ, ਨਹੀਂ, ਜੋੜਿਆ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"ਲਿਊ ਨੇ ਕਿਹਾ, ਇਸ ਸਭ ਤੋਂ ਚੀਨ - ਭਾਰਤ ਸੀਮਾ ਪਾਰ ਵਿ...</td>\n",
       "      <td>[[\"ਲਿਊ, ਨੇ, ਕਿਹਾ,, ਇਸ, ਸਭ, ਤੋਂ, ਚੀਨ, -, ਭਾਰਤ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"ਉਸ ਮੁਤਾਬਿਕ ਅਗਲੀ ਕਾਰਵਾਈ ਕੀਤੀ ਜਾਵੇਗੀ।\"</td>\n",
       "      <td>[[\"ਉਸ, ਮੁਤਾਬਿਕ, ਅਗਲੀ, ਕਾਰਵਾਈ, ਕੀਤੀ, ਜਾਵੇਗੀ।\"]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"ਕਈ ਸਾਲ ਬੀਤ ਗਏ ਅਤੇ ਸ਼ੇਲਾਹ ਵੱਡਾ ਹੋ ਗਿਆ ।\"</td>\n",
       "      <td>[[\"ਕਈ, ਸਾਲ, ਬੀਤ, ਗਏ, ਅਤੇ, ਸ਼ੇਲਾਹ, ਵੱਡਾ, ਹੋ, ਗਿ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \"ਖੇਤੀਬਾੜੀ ਮੰਤਰਾਲਾ ਰਾਜਸਥਾਨ, ਮੱਧ ਪ੍ਰਦੇਸ਼, ਪੰਜਾਬ,...   \n",
       "1  \"ਅੱਤਵਾਦ ਨੂੰ ਕਿਸੇੇ ਧਰਮ ਨਾਲ ਨਹੀਂ ਜੋੜਿਆ ਜਾ ਸਕਦਾ, ...   \n",
       "2  \"ਲਿਊ ਨੇ ਕਿਹਾ, ਇਸ ਸਭ ਤੋਂ ਚੀਨ - ਭਾਰਤ ਸੀਮਾ ਪਾਰ ਵਿ...   \n",
       "3              \"ਉਸ ਮੁਤਾਬਿਕ ਅਗਲੀ ਕਾਰਵਾਈ ਕੀਤੀ ਜਾਵੇਗੀ।\"   \n",
       "4           \"ਕਈ ਸਾਲ ਬੀਤ ਗਏ ਅਤੇ ਸ਼ੇਲਾਹ ਵੱਡਾ ਹੋ ਗਿਆ ।\"   \n",
       "\n",
       "                                              tokens  \n",
       "0  [[\"ਖੇਤੀਬਾੜੀ, ਮੰਤਰਾਲਾ, ਰਾਜਸਥਾਨ,, ਮੱਧ, ਪ੍ਰਦੇਸ਼,,...  \n",
       "1  [[\"ਅੱਤਵਾਦ, ਨੂੰ, ਕਿਸੇੇ, ਧਰਮ, ਨਾਲ, ਨਹੀਂ, ਜੋੜਿਆ, ...  \n",
       "2  [[\"ਲਿਊ, ਨੇ, ਕਿਹਾ,, ਇਸ, ਸਭ, ਤੋਂ, ਚੀਨ, -, ਭਾਰਤ, ...  \n",
       "3     [[\"ਉਸ, ਮੁਤਾਬਿਕ, ਅਗਲੀ, ਕਾਰਵਾਈ, ਕੀਤੀ, ਜਾਵੇਗੀ।\"]]  \n",
       "4  [[\"ਕਈ, ਸਾਲ, ਬੀਤ, ਗਏ, ਅਤੇ, ਸ਼ੇਲਾਹ, ਵੱਡਾ, ਹੋ, ਗਿ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69405413",
   "metadata": {},
   "source": [
    "Remove all sentence which doesn’t fall under cartain length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ce53246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1636898/1636898 [00:55<00:00, 29641.27it/s]\n"
     ]
    }
   ],
   "source": [
    "def filter_sent_by_length(sents, min_length = 8, max_length = 29):\n",
    "    filtered_sents = []\n",
    "\n",
    "    for idx, row in tqdm(sents.iterrows(), total=len(sents)):\n",
    "        for s in row[\"tokens\"]:\n",
    "            if len(s) > max_length:\n",
    "                continue\n",
    "\n",
    "            if len(s) < min_length:\n",
    "                continue\n",
    "\n",
    "            filtered_sents.append({\n",
    "                \"sent\": \" \".join(s),\n",
    "                \"words\": s,\n",
    "                \n",
    "                })\n",
    "\n",
    "    filtered_sents = pd.DataFrame(filtered_sents)\n",
    "    return filtered_sents\n",
    "\n",
    "min_length = 8 #You could change this\n",
    "max_length = 29 #You could change this\n",
    "\n",
    "#You need to include your language specific minimum and maximum sentence length\n",
    "selected_targets = filter_sent_by_length(target, min_length = 8, max_length = 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b337b1",
   "metadata": {},
   "source": [
    "Select `n` sentences which have rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "883ca056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sents w/ rare words 163833\n",
      "Sents w/o rare words 916935\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def select_sents_by_rare_words(selected_terms, target_sents):\n",
    "\n",
    "    candidateidx = set()\n",
    "    keywords = defaultdict(list)\n",
    "\n",
    "    for _, row in selected_terms.iterrows():\n",
    "        try:\n",
    "            docs = target_sents[target_sents[\"sent\"].str.contains(row[\"term\"], regex=False)]\n",
    "            candidateidx.update(docs.index.to_list())\n",
    "            for i in docs.index.to_list():\n",
    "                keywords[i].append(row[\"term\"])\n",
    "        except Exception as e:\n",
    "            print(row)\n",
    "            print(e)\n",
    "\n",
    "    candidateidx = list(candidateidx)\n",
    "    rare_word_sents = target_sents.loc[candidateidx]\n",
    "    print(\"Sents w/ rare words\", len(rare_word_sents))\n",
    "\n",
    "    for i in keywords:\n",
    "        if i in rare_word_sents.index:\n",
    "            rare_word_sents.loc[i, \"keywords\"] = \",\".join(keywords[i])\n",
    "\n",
    "    # Shuffle\n",
    "    rare_word_sents.sample(frac=1)\n",
    "    \n",
    "    non_rare_word_sents = target_sents.loc[~target_sents.index.isin(candidateidx)]\n",
    "    print(\"Sents w/o rare words\", len(non_rare_word_sents))\n",
    "    \n",
    "    return rare_word_sents, non_rare_word_sents\n",
    "\n",
    "rare_word_sents, non_rare_word_sents = select_sents_by_rare_words(selected_terms, selected_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4f882",
   "metadata": {},
   "source": [
    "Resample sentences based on categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "932205a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #You need to change based on your categories name\n",
    "\n",
    "# categories = [\n",
    "#  'cat1',\n",
    "#  'cat2'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cb2b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_by_text(sents, nsample = 100):\n",
    "    # candidates = set()\n",
    "    # for cat in categories:\n",
    "    #     _sents = sents[sents[\"category\"].str.contains(cat, regex=False)]\n",
    "    #     if len(_sents)>0:\n",
    "    #         _sents = _sents.sample(n=nsample)\n",
    "    #         candidates.update(_sents.index.to_list())\n",
    "\n",
    "    # sampled_sents = sents.loc[list(candidates)]\n",
    "    sampled_sents = sents.sample(n=nsample)\n",
    "    return sampled_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "784777d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>words</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>961229</th>\n",
       "      <td>\"ਪ੍ਰਚਾਰਕ ਹੋਣ ਦੇ ਨਾਤੇ ਸਾਨੂੰ ਵੀ ਇੱਦਾਂ ਹੀ ਕਰਨ ਦੀ ...</td>\n",
       "      <td>[\"ਪ੍ਰਚਾਰਕ, ਹੋਣ, ਦੇ, ਨਾਤੇ, ਸਾਨੂੰ, ਵੀ, ਇੱਦਾਂ, ਹੀ...</td>\n",
       "      <td>\"ਪ੍ਰਚਾਰਕ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45308</th>\n",
       "      <td>\"ਫੌਜ ਮੁਖੀ ਵੱਲੋਂ ਸ਼ੌਪੀਆਂ 'ਚ ਸ਼ਹੀਦ ਹੋਏ ਸੈਨਿਕਾਂ ਨੂੰ...</td>\n",
       "      <td>[\"ਫੌਜ, ਮੁਖੀ, ਵੱਲੋਂ, ਸ਼ੌਪੀਆਂ, 'ਚ, ਸ਼ਹੀਦ, ਹੋਏ, ਸੈਨ...</td>\n",
       "      <td>ਸ਼ਰਧਾਂਜਲ,ਸ਼ਰਧਾਂਜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414396</th>\n",
       "      <td>\"ਪੁਲਿਸ ਦੇ ਦੁਆਰਾ ਇਨ੍ਹਾਂ ਦੋਸ਼ੀਆਂ ਨੂੰ ਗ੍ਰਿਫਤਾਰ ਕਰਕ...</td>\n",
       "      <td>[\"ਪੁਲਿਸ, ਦੇ, ਦੁਆਰਾ, ਇਨ੍ਹਾਂ, ਦੋਸ਼ੀਆਂ, ਨੂੰ, ਗ੍ਰਿਫ...</td>\n",
       "      <td>ੱਖ-ਵੱਖ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169751</th>\n",
       "      <td>\"ਪੁਲਿਸ ਅਧਿਕਾਰੀ ਨੇ ਦੱਸਿਆ ਕਿ ਪੋਸਟ–ਮਾਰਟਮ ਤੋਂ ਬਾਅਦ...</td>\n",
       "      <td>[\"ਪੁਲਿਸ, ਅਧਿਕਾਰੀ, ਨੇ, ਦੱਸਿਆ, ਕਿ, ਪੋਸਟ–ਮਾਰਟਮ, ਤ...</td>\n",
       "      <td>ਜਾਵੇਗੀ।\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>\"ਉਨ੍ਹਾਂ ਨੇ ਈਟਾਨਗਰ ਦੇ ਆਈਜੀ ਪਾਰਕ ਤੋਂ ਕਈ ਹੋਰ ਵਿਕਾ...</td>\n",
       "      <td>[\"ਉਨ੍ਹਾਂ, ਨੇ, ਈਟਾਨਗਰ, ਦੇ, ਆਈਜੀ, ਪਾਰਕ, ਤੋਂ, ਕਈ,...</td>\n",
       "      <td>ਪ੍ਰੋਜੈਕ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332183</th>\n",
       "      <td>\"ਸਕੂਲ ਦੇ ਚਾਰ ਹਾਉੂਸਾਂ ਦੇ ਵਿਦਿਆਰਥੀਆਂ ਨੇ ਇਸ 'ਚ ਵੱ...</td>\n",
       "      <td>[\"ਸਕੂਲ, ਦੇ, ਚਾਰ, ਹਾਉੂਸਾਂ, ਦੇ, ਵਿਦਿਆਰਥੀਆਂ, ਨੇ, ...</td>\n",
       "      <td>ਹਾਉੂਸਾਂ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528619</th>\n",
       "      <td>\"ਅਪਰਾਧਿਕ ਮਾਣਹਾਨੀ ਮਾਮਲੇ 'ਚ ਦਿੱਲੀ ਹਾਈਕੋਰਟ ਵਲੋਂ ਕ...</td>\n",
       "      <td>[\"ਅਪਰਾਧਿਕ, ਮਾਣਹਾਨੀ, ਮਾਮਲੇ, 'ਚ, ਦਿੱਲੀ, ਹਾਈਕੋਰਟ,...</td>\n",
       "      <td>ਕੇਜਰੀਵ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47941</th>\n",
       "      <td>\"’ ਉਨ੍ਹਾਂ ਕਿਹਾ ਕਿ ਸਰਕਾਰ ਨੂੰ ਕੁਝ ਨਹੀਂ ਸੁੱਝ ਰਿਹਾ।\"</td>\n",
       "      <td>[\"’, ਉਨ੍ਹਾਂ, ਕਿਹਾ, ਕਿ, ਸਰਕਾਰ, ਨੂੰ, ਕੁਝ, ਨਹੀਂ, ...</td>\n",
       "      <td>ਰਿਹਾ।\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622324</th>\n",
       "      <td>\"ਸੜਕ ਹਾਦਸੇ 'ਚ ਏਅਰ ਫੋਰਸ ਦੇ ਮੁਲਾਜ਼ਮ ਦੀ ਮੌਤ\"</td>\n",
       "      <td>[\"ਸੜਕ, ਹਾਦਸੇ, 'ਚ, ਏਅਰ, ਫੋਰਸ, ਦੇ, ਮੁਲਾਜ਼ਮ, ਦੀ, ...</td>\n",
       "      <td>ਮੁਲਾਜ਼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738442</th>\n",
       "      <td>\"ਵੈਸਟਇੰਡੀਜ਼-ਡਵੇਨ ਬ੍ਰਾਵੋ (ਕਪਤਾਨ), ਕ੍ਰਿਸ ਗੇਲ, ਜੌਨ...</td>\n",
       "      <td>[\"ਵੈਸਟਇੰਡੀਜ਼-ਡਵੇਨ, ਬ੍ਰਾਵੋ, (ਕਪਤਾਨ),, ਕ੍ਰਿਸ, ਗੇਲ...</td>\n",
       "      <td>ਵੈਸਟਇੰ,ਵੈਸਟਇੰਡ,ਸੈਮੁਅਲਜ਼,,ਵੈਸਟਇੰਡੀਜ਼-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     sent  \\\n",
       "961229  \"ਪ੍ਰਚਾਰਕ ਹੋਣ ਦੇ ਨਾਤੇ ਸਾਨੂੰ ਵੀ ਇੱਦਾਂ ਹੀ ਕਰਨ ਦੀ ...   \n",
       "45308   \"ਫੌਜ ਮੁਖੀ ਵੱਲੋਂ ਸ਼ੌਪੀਆਂ 'ਚ ਸ਼ਹੀਦ ਹੋਏ ਸੈਨਿਕਾਂ ਨੂੰ...   \n",
       "414396  \"ਪੁਲਿਸ ਦੇ ਦੁਆਰਾ ਇਨ੍ਹਾਂ ਦੋਸ਼ੀਆਂ ਨੂੰ ਗ੍ਰਿਫਤਾਰ ਕਰਕ...   \n",
       "169751  \"ਪੁਲਿਸ ਅਧਿਕਾਰੀ ਨੇ ਦੱਸਿਆ ਕਿ ਪੋਸਟ–ਮਾਰਟਮ ਤੋਂ ਬਾਅਦ...   \n",
       "7474    \"ਉਨ੍ਹਾਂ ਨੇ ਈਟਾਨਗਰ ਦੇ ਆਈਜੀ ਪਾਰਕ ਤੋਂ ਕਈ ਹੋਰ ਵਿਕਾ...   \n",
       "...                                                   ...   \n",
       "332183  \"ਸਕੂਲ ਦੇ ਚਾਰ ਹਾਉੂਸਾਂ ਦੇ ਵਿਦਿਆਰਥੀਆਂ ਨੇ ਇਸ 'ਚ ਵੱ...   \n",
       "528619  \"ਅਪਰਾਧਿਕ ਮਾਣਹਾਨੀ ਮਾਮਲੇ 'ਚ ਦਿੱਲੀ ਹਾਈਕੋਰਟ ਵਲੋਂ ਕ...   \n",
       "47941    \"’ ਉਨ੍ਹਾਂ ਕਿਹਾ ਕਿ ਸਰਕਾਰ ਨੂੰ ਕੁਝ ਨਹੀਂ ਸੁੱਝ ਰਿਹਾ।\"   \n",
       "622324          \"ਸੜਕ ਹਾਦਸੇ 'ਚ ਏਅਰ ਫੋਰਸ ਦੇ ਮੁਲਾਜ਼ਮ ਦੀ ਮੌਤ\"   \n",
       "738442  \"ਵੈਸਟਇੰਡੀਜ਼-ਡਵੇਨ ਬ੍ਰਾਵੋ (ਕਪਤਾਨ), ਕ੍ਰਿਸ ਗੇਲ, ਜੌਨ...   \n",
       "\n",
       "                                                    words  \\\n",
       "961229  [\"ਪ੍ਰਚਾਰਕ, ਹੋਣ, ਦੇ, ਨਾਤੇ, ਸਾਨੂੰ, ਵੀ, ਇੱਦਾਂ, ਹੀ...   \n",
       "45308   [\"ਫੌਜ, ਮੁਖੀ, ਵੱਲੋਂ, ਸ਼ੌਪੀਆਂ, 'ਚ, ਸ਼ਹੀਦ, ਹੋਏ, ਸੈਨ...   \n",
       "414396  [\"ਪੁਲਿਸ, ਦੇ, ਦੁਆਰਾ, ਇਨ੍ਹਾਂ, ਦੋਸ਼ੀਆਂ, ਨੂੰ, ਗ੍ਰਿਫ...   \n",
       "169751  [\"ਪੁਲਿਸ, ਅਧਿਕਾਰੀ, ਨੇ, ਦੱਸਿਆ, ਕਿ, ਪੋਸਟ–ਮਾਰਟਮ, ਤ...   \n",
       "7474    [\"ਉਨ੍ਹਾਂ, ਨੇ, ਈਟਾਨਗਰ, ਦੇ, ਆਈਜੀ, ਪਾਰਕ, ਤੋਂ, ਕਈ,...   \n",
       "...                                                   ...   \n",
       "332183  [\"ਸਕੂਲ, ਦੇ, ਚਾਰ, ਹਾਉੂਸਾਂ, ਦੇ, ਵਿਦਿਆਰਥੀਆਂ, ਨੇ, ...   \n",
       "528619  [\"ਅਪਰਾਧਿਕ, ਮਾਣਹਾਨੀ, ਮਾਮਲੇ, 'ਚ, ਦਿੱਲੀ, ਹਾਈਕੋਰਟ,...   \n",
       "47941   [\"’, ਉਨ੍ਹਾਂ, ਕਿਹਾ, ਕਿ, ਸਰਕਾਰ, ਨੂੰ, ਕੁਝ, ਨਹੀਂ, ...   \n",
       "622324  [\"ਸੜਕ, ਹਾਦਸੇ, 'ਚ, ਏਅਰ, ਫੋਰਸ, ਦੇ, ਮੁਲਾਜ਼ਮ, ਦੀ, ...   \n",
       "738442  [\"ਵੈਸਟਇੰਡੀਜ਼-ਡਵੇਨ, ਬ੍ਰਾਵੋ, (ਕਪਤਾਨ),, ਕ੍ਰਿਸ, ਗੇਲ...   \n",
       "\n",
       "                                  keywords  \n",
       "961229                            \"ਪ੍ਰਚਾਰਕ  \n",
       "45308                       ਸ਼ਰਧਾਂਜਲ,ਸ਼ਰਧਾਂਜ  \n",
       "414396                              ੱਖ-ਵੱਖ  \n",
       "169751                            ਜਾਵੇਗੀ।\"  \n",
       "7474                               ਪ੍ਰੋਜੈਕ  \n",
       "...                                    ...  \n",
       "332183                             ਹਾਉੂਸਾਂ  \n",
       "528619                              ਕੇਜਰੀਵ  \n",
       "47941                               ਰਿਹਾ।\"  \n",
       "622324                              ਮੁਲਾਜ਼  \n",
       "738442  ਵੈਸਟਇੰ,ਵੈਸਟਇੰਡ,ਸੈਮੁਅਲਜ਼,,ਵੈਸਟਇੰਡੀਜ਼-  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nsample = number of sentences from each category\n",
    "nsample = 4000 #You need to change this\n",
    "sampled_rare_word_sents = sample_by_text(rare_word_sents,nsample)\n",
    "sampled_rare_word_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db144743",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_word_file = data_dir + '/rare_word_'+ target_file\n",
    "sampled_rare_word_sents.to_csv(rare_word_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c5d17",
   "metadata": {},
   "source": [
    "Select `n` sentences which **don't** have rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91765d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308348</th>\n",
       "      <td>\"ਇਸ ਸਬੰਧੀ ਸਾਰੀਆਂ ਤਿਆਰੀਆਂ ਮਕੁੰਮਲ ਕਰ ਲਈਆ ਗਈਆਂ ਹਨ।\"</td>\n",
       "      <td>[\"ਇਸ, ਸਬੰਧੀ, ਸਾਰੀਆਂ, ਤਿਆਰੀਆਂ, ਮਕੁੰਮਲ, ਕਰ, ਲਈਆ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42297</th>\n",
       "      <td>\"ਇੱਦਾਂ ਕਰ ਕੇ ਅਸੀਂ ਵੀ ਪੌਲੁਸ ਵਾਂਗ ਦਿਖਾਉਂਦੇ ਹਾਂ ਕ...</td>\n",
       "      <td>[\"ਇੱਦਾਂ, ਕਰ, ਕੇ, ਅਸੀਂ, ਵੀ, ਪੌਲੁਸ, ਵਾਂਗ, ਦਿਖਾਉਂ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407483</th>\n",
       "      <td>\"ਇਸ ਤੋਂ ਇਲਾਵਾ ਰਾਸ਼ਟਰਪਤੀ ਰਾਮਨਾਥ ਕੋਵਿੰਦ, ਕੇਂਦਰੀ ਗ...</td>\n",
       "      <td>[\"ਇਸ, ਤੋਂ, ਇਲਾਵਾ, ਰਾਸ਼ਟਰਪਤੀ, ਰਾਮਨਾਥ, ਕੋਵਿੰਦ,, ਕ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244385</th>\n",
       "      <td>\"ਪੁਲਿਸ ਨੇ ਦੋਸ਼ੀਆਂ ਤੋਂ ਬਾਇਕ ਅਤੇ ਲੁੱਟ ਖੋਹ ਕੀਤਾ ਗਿ...</td>\n",
       "      <td>[\"ਪੁਲਿਸ, ਨੇ, ਦੋਸ਼ੀਆਂ, ਤੋਂ, ਬਾਇਕ, ਅਤੇ, ਲੁੱਟ, ਖੋਹ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257666</th>\n",
       "      <td>\"ਉਸ ਦੀ ਤਸਵੀਰ ਸੀਸੀਟੀਵੀ ਕੈਮਰੇ `ਚ ਕੈਦ ਹੋ ਗਈ ਹੈ।\"</td>\n",
       "      <td>[\"ਉਸ, ਦੀ, ਤਸਵੀਰ, ਸੀਸੀਟੀਵੀ, ਕੈਮਰੇ, `ਚ, ਕੈਦ, ਹੋ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419289</th>\n",
       "      <td>\"ਇਸ ਤੋਂ ਇਲਾਵਾ ਬੀਤੇ ਦਿਨ ਹੀ ਧਾਰਾ 144 ਵੀ ਲਾਗੂ ਹੈ।\"</td>\n",
       "      <td>[\"ਇਸ, ਤੋਂ, ਇਲਾਵਾ, ਬੀਤੇ, ਦਿਨ, ਹੀ, ਧਾਰਾ, 144, ਵੀ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224877</th>\n",
       "      <td>\"ਜੇ ਉਹ ਪੜ੍ਹ ਨਹੀਂ ਸਕਦੇ ਤਾਂ ਉਨ੍ਹਾਂ ਨੂੰ ਪੜ੍ਹਨਾ ਸਿ...</td>\n",
       "      <td>[\"ਜੇ, ਉਹ, ਪੜ੍ਹ, ਨਹੀਂ, ਸਕਦੇ, ਤਾਂ, ਉਨ੍ਹਾਂ, ਨੂੰ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523024</th>\n",
       "      <td>\"ਦੱਖਣੀ ਏਸ਼ੀਆ ਦੀ ਪਹਿਲੀ ਭਾਰਤ-ਨੇਪਾਲ ਪੈਟਰੋਲੀਅਮ ਪਾਈਪ...</td>\n",
       "      <td>[\"ਦੱਖਣੀ, ਏਸ਼ੀਆ, ਦੀ, ਪਹਿਲੀ, ਭਾਰਤ-ਨੇਪਾਲ, ਪੈਟਰੋਲੀਅ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250738</th>\n",
       "      <td>\"ਚੰਦਨ ਪਾਊਡਰ ਦੀ ਥੋੜ੍ਹੀ ਜਿਹੀ ਮਾਤਰਾ ਲੈ ਕੇ ਇਸ ਵਿੱਚ...</td>\n",
       "      <td>[\"ਚੰਦਨ, ਪਾਊਡਰ, ਦੀ, ਥੋੜ੍ਹੀ, ਜਿਹੀ, ਮਾਤਰਾ, ਲੈ, ਕੇ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368939</th>\n",
       "      <td>\"ਮੈਂ ਟੀ ਵੀ 'ਤੇ ਵੇਖਿਆ ਕਿ ਸਾਡੇ ਪੰਜ ਨਾਗਰਿਕ ਮਾਰੇ ਗਏ।\"</td>\n",
       "      <td>[\"ਮੈਂ, ਟੀ, ਵੀ, 'ਤੇ, ਵੇਖਿਆ, ਕਿ, ਸਾਡੇ, ਪੰਜ, ਨਾਗਰ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     sent  \\\n",
       "308348   \"ਇਸ ਸਬੰਧੀ ਸਾਰੀਆਂ ਤਿਆਰੀਆਂ ਮਕੁੰਮਲ ਕਰ ਲਈਆ ਗਈਆਂ ਹਨ।\"   \n",
       "42297   \"ਇੱਦਾਂ ਕਰ ਕੇ ਅਸੀਂ ਵੀ ਪੌਲੁਸ ਵਾਂਗ ਦਿਖਾਉਂਦੇ ਹਾਂ ਕ...   \n",
       "407483  \"ਇਸ ਤੋਂ ਇਲਾਵਾ ਰਾਸ਼ਟਰਪਤੀ ਰਾਮਨਾਥ ਕੋਵਿੰਦ, ਕੇਂਦਰੀ ਗ...   \n",
       "244385  \"ਪੁਲਿਸ ਨੇ ਦੋਸ਼ੀਆਂ ਤੋਂ ਬਾਇਕ ਅਤੇ ਲੁੱਟ ਖੋਹ ਕੀਤਾ ਗਿ...   \n",
       "257666      \"ਉਸ ਦੀ ਤਸਵੀਰ ਸੀਸੀਟੀਵੀ ਕੈਮਰੇ `ਚ ਕੈਦ ਹੋ ਗਈ ਹੈ।\"   \n",
       "...                                                   ...   \n",
       "419289    \"ਇਸ ਤੋਂ ਇਲਾਵਾ ਬੀਤੇ ਦਿਨ ਹੀ ਧਾਰਾ 144 ਵੀ ਲਾਗੂ ਹੈ।\"   \n",
       "224877  \"ਜੇ ਉਹ ਪੜ੍ਹ ਨਹੀਂ ਸਕਦੇ ਤਾਂ ਉਨ੍ਹਾਂ ਨੂੰ ਪੜ੍ਹਨਾ ਸਿ...   \n",
       "523024  \"ਦੱਖਣੀ ਏਸ਼ੀਆ ਦੀ ਪਹਿਲੀ ਭਾਰਤ-ਨੇਪਾਲ ਪੈਟਰੋਲੀਅਮ ਪਾਈਪ...   \n",
       "250738  \"ਚੰਦਨ ਪਾਊਡਰ ਦੀ ਥੋੜ੍ਹੀ ਜਿਹੀ ਮਾਤਰਾ ਲੈ ਕੇ ਇਸ ਵਿੱਚ...   \n",
       "368939  \"ਮੈਂ ਟੀ ਵੀ 'ਤੇ ਵੇਖਿਆ ਕਿ ਸਾਡੇ ਪੰਜ ਨਾਗਰਿਕ ਮਾਰੇ ਗਏ।\"   \n",
       "\n",
       "                                                    words  \n",
       "308348  [\"ਇਸ, ਸਬੰਧੀ, ਸਾਰੀਆਂ, ਤਿਆਰੀਆਂ, ਮਕੁੰਮਲ, ਕਰ, ਲਈਆ,...  \n",
       "42297   [\"ਇੱਦਾਂ, ਕਰ, ਕੇ, ਅਸੀਂ, ਵੀ, ਪੌਲੁਸ, ਵਾਂਗ, ਦਿਖਾਉਂ...  \n",
       "407483  [\"ਇਸ, ਤੋਂ, ਇਲਾਵਾ, ਰਾਸ਼ਟਰਪਤੀ, ਰਾਮਨਾਥ, ਕੋਵਿੰਦ,, ਕ...  \n",
       "244385  [\"ਪੁਲਿਸ, ਨੇ, ਦੋਸ਼ੀਆਂ, ਤੋਂ, ਬਾਇਕ, ਅਤੇ, ਲੁੱਟ, ਖੋਹ...  \n",
       "257666  [\"ਉਸ, ਦੀ, ਤਸਵੀਰ, ਸੀਸੀਟੀਵੀ, ਕੈਮਰੇ, `ਚ, ਕੈਦ, ਹੋ,...  \n",
       "...                                                   ...  \n",
       "419289  [\"ਇਸ, ਤੋਂ, ਇਲਾਵਾ, ਬੀਤੇ, ਦਿਨ, ਹੀ, ਧਾਰਾ, 144, ਵੀ...  \n",
       "224877  [\"ਜੇ, ਉਹ, ਪੜ੍ਹ, ਨਹੀਂ, ਸਕਦੇ, ਤਾਂ, ਉਨ੍ਹਾਂ, ਨੂੰ, ...  \n",
       "523024  [\"ਦੱਖਣੀ, ਏਸ਼ੀਆ, ਦੀ, ਪਹਿਲੀ, ਭਾਰਤ-ਨੇਪਾਲ, ਪੈਟਰੋਲੀਅ...  \n",
       "250738  [\"ਚੰਦਨ, ਪਾਊਡਰ, ਦੀ, ਥੋੜ੍ਹੀ, ਜਿਹੀ, ਮਾਤਰਾ, ਲੈ, ਕੇ...  \n",
       "368939  [\"ਮੈਂ, ਟੀ, ਵੀ, 'ਤੇ, ਵੇਖਿਆ, ਕਿ, ਸਾਡੇ, ਪੰਜ, ਨਾਗਰ...  \n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsample = 4000 #You nee to change this\n",
    "sampled_non_rare_word_sents = sample_by_text(non_rare_word_sents,nsample)\n",
    "sampled_non_rare_word_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0cf4837",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rare_word_file = data_dir + '/non_rare_word_'+ target_file\n",
    "sampled_non_rare_word_sents.to_csv(non_rare_word_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
